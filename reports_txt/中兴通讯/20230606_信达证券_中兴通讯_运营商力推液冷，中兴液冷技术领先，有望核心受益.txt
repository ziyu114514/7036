运营商力推液冷，中兴液冷技术领先，有望核心受益
公司研究
2023年6月6日
点评报告
事件: 6 月 5 日, 在 31 届中国国际信息通信展览会上,中国移动、中国电
信、中国联通三家基础电信运营企业共同面向业界发布了《电信运营商液冷
中兴通讯(000063.SZ)
技术白皮书》。
投资评级
点评:
上次评级
运营商力推液冷应用，液冷渗透率有望提升，中兴通讯有望核心受益
为推进电信运营商液冷技术应用,《电信运营商液冷技术白皮书》提出“三年
景愿”,即 2023 年开展液冷技术验证; 2024 年开展规模测试,新建数据中
心项目 10%规模试点应用液冷技术，推进产业生态成熟; 2025 年及以后开
展规模应用,50%以上数据中心项目应用液冷技术。
中兴通讯是运营商算力产业链核心合作伙伴,公司连续2年取得国内运营商
服务器市场份额第一,2022年运营商市场 X86 服务器以17.5 万台的发货量
位居首位,公司已提前深度布局液冷技术:
1) IDC 机房侧:公司已完成单板级、插箱级、机柜级、机房级四个不同维度
的液冷技术攻关,于 23 年 Q1 推出全液冷系统解决方案,实现 DC 液冷数据
蒋 颖
中心机房、IT 液冷服务器设备、CT 液冷路由交换设备一体化集成开发、交
付,整机能耗预计可降低约 5%,液冷数据中心 PUE 可降至 1.2 以下;
执业编号：$1500521010002
2) 服务器侧:全新 G5 系列服务器支持不同的冷板式液冷方案，如 CPU 液
冷、CPU+内存条液冷,以及 CPU+内存条散热+VR 液冷,冷板液冷占比最
高可达80%以上,充分满足不同制冷需求,浸没式液冷方案还在研发当中;
3)液冷路由器:中兴通讯与中国电信研究院和中国电信云计算公司联合建设
T8000 核心路由器的冷板式液冷试验局。试验局实现核心芯片运行温度降低
10℃, 理论故障率约减少一半; 大容量核心机房综合 PUE≤1.2, 解决了高功
相关研究
率路由器空调散热难的问题。
《中兴通讯深度报告:全面布局
智能汽车，多项业务持续落地-
公司作为全球领先的综合性通信制造业公司和全球通信解决方案提供商，致
力于将液冷技术应用到通信领域，我们认为公司作为运营商算力产业链核心
智能网联汽车系列（1）》
合作伙伴，在未来运营商液冷数据中心项目的建设中有望率先受益。
《中兴通讯:全屏实力全球领先,
消费电子王者归来——价值变现系
列深度 2（消费电子篇）》
信达证券股份有限公司
CINDA SECURITIES CO., LTD
北京市西城区闹市口大街9号院1号楼
运营商服务器市场: 服务器产品实力强劲, 在多个运营商项目中排名均位列第一
\triangleright
我们认为 2023 年数字经济建设是国家发展主线之一, 算网基础设施建设或将逐步加快,
2023 年三大运营商在算力方面的资本开支均保持 20%以上增速，中兴通讯有望核心受益。
1)公司在中国电信 2022-2023 年服务器集中采购中实现全标包入围,总份额第一,其中标
包1、4、6中排名第一,标包2、3、7中位列第二。
2)公司在中国联通 2022 云服务器集中采购中总份额第一,其中标包 1 排名第一;在 2022-
2024 年中国联通国际服务器集中采购标段 1 中排名第二;在 2022 年中国联通人工智能服
务器集中采购中排名第三;在 2022 年中国联通通用服务器集采中总份额第二。
3)公司在中国移动 2019-2020、2020PC 服务器集采、2021-2022PC 服务器集采(网络云
标包)中均排名第一:在中国移动 2021-2022PC 服务器集采(第一批次)中总份额位列第
二；在中国移动 2021-2022PC 服务器集采（第二批次，1-6 标包）中总份额排名第三；在
中国移动 2022 政企客户算力服务器集采中排名第二;在中国移动集中网络云资源池第三期
工程计算型服务器采购中排名第一。
> AI服务器:产品性能强劲,成为“文心一言”可靠算力底座
3月16日,据中兴通讯微信公众号,中兴通讯和百度联合宣布,中兴通讯服务器将支持百
度“文心一言”,为 AI 产品应用提供更加强劲的算力支撑,助力 AI 产业化应用和生态繁荣。
“文心一言”是百度基于文心大模型技术推出的生成式 AI 产品，具备跨模态、跨语言的深
度语义理解与生成能力,“文心一言”将通过百度智能云对外提供服务,为产业带来 AI 普惠。
在服务器产品方面,公司服务器产品全面满足百度定制化要求,针对百度智能云 AI、深度学
习的需求，中兴通讯服务器产品采用高密度、模块化、精细化设计，具有高性能、高可靠、
易扩展、易管理等优势，在 AI、云计算、大数据、NFV 等领域具有出色的表现，适用于百
度大脑、飞桨深度学习平台。目前，公司服务器产品已规模应用于百度智能云，充分满足百
度智能云不同业务场景差异化配置需求、资源分配和上云服务。我们认为此次合作体现了公
司在提供 AI 服务器解决方案的强大实力, 公司服务器产品可充分满足 AI 模型所需的蓬勃算
力需求和庞大的数据吞吐量需求。未来，随着国产 AI 模型持续发展，AI 下游应用的落地，
模型推理算力需求有望带动公司 AI 服务器持续放量。
截至目前，公司最新的 R6500 G5 GPU 服务器可支持 20 张单宽半长 GPU 加速卡，具备高
密度算力、灵活扩展、异构算力、海量存储、稳定可靠等特性, 双路最大支持 120 核, AI 性
能提升 10 倍, 为数字经济发展提供强大算力支持。在中兴通讯 2022 年年报解读交流会上,
公司表示年底有望推出支持 Chatgpt 的 GPU 服务器以及高性能交换机, 2023 年运营商数
据中心交换机营收有望倍增，同时公司是全球领先的 ICT 解决方案提供商，研发实力强劲，
我们看好公司强劲技术研发实力在 AI 等新应用领域的持续价值变现。
服务器方面: 市场份额快速提升, 保持较高增速
\triangleright
据 IDC 数据，2022 年中国服务器市场规模为 273.4 亿美元 ( 1888.37 亿人民币 )，同比增
长 9.1%,中兴通讯 2022 年服务器收入已达 100.08 亿元;根据中兴通讯官网,2022 年,
中兴通讯服务器及存储营业收入百亿元,同比增长近80%;据 IDC 2022 年第四季度中国服
务器市场跟踪报告，Top8 服务器厂商中，浪潮、戴尔、联想份额均出现下滑，超聚变和中
兴则取得明显增长,其中中兴通讯市场份额从3.1%提升至5.3%,位居国内第五。公司在今
年新产品发布会上表示将快步实现服务器及储存产品国内前三( 按照 2022 年份额超 10%以
上)、全球前五的经营愿景。
谷歌、Meta、百度等深度学习库均已接入中兴 Adlik 架构, 长期需求有望持续释放
2022 年 12 月 28 日,公司联合英特尔共同发布《英特尔联手中兴优化深度学习模型推理,
实现降本增效》白皮书，本白皮书深入介绍了中兴通讯主导的开源项目 Adlik 如何与英特尔
OpenVINO 工具结合。为解决购买专用 GPU 硬件会大幅增加部署成本，而且应用范围有
限,灵活度较低的问题,中兴通讯通过硬件创新和软件层面的深度优化,在部分场景中,如
果能够直接使用 CPU 来进行推理，将有助于降低成本，提升灵活度，白皮书指出通过中兴
Adlik 可以对 AI 模型进行自动剪枝、蒸馏，实现模型大小的优化，再通过 OpenVINO™的量
化工具和推理引擎,对模型实现 INT8 量化,从而实现模型压缩,以降低模型推理所需的计
算资源和内存带宽，提高模型的推理性能。通过使用中兴 Adlik+第三代英特尔®至强®可扩
展处理器+ OpenVINO™工具套件的组合，可使已完成训练的高精度 AI 模型转换成参数较
小、结构简单、精度基本不下降的 AI 小模型, 其性能与大模型接近, 模型数据吞吐量更高,
从而实现在不增加 GPU 硬件，大幅减少部署成本的情况下，直接使用 CPU 服务器即可满
足模型的日常推理需求，成功实现降本增效，并使得模型更易部署在算力有限的场景下，比
如自动驾驶车端场景。我们认为此解决方案能够实现 AI 模型推理的降本增效，适用各垂直
领域的 AI 小模型有望加速落地,充分满足不同场景需求。
Adlik 是用于将深度学习模型从训练完成到部署到特定硬件,提供应用服务的端到端工具链,
其应用目的是为了将模型从研发产 品快速部署到生产应用环境。Adlik 可以和多种推理引
擎协作， 支持多款硬件，提供统一对外推理接口，并提供多种灵活的部署方案。目前谷歌
TensorFLOW，Meta PyTorch 和百度的 PP 飞桨深度学习库都已能够接入 Adlik 架构。随
着 Meta AI SAM 开源图像分割模型的问世，计算机视觉产业或将加速发展。由于 SAM 中
的图像编码器功能必须在 PyTorch 中实现, 并需要 GPU 才能进行高效推理, 我们认为计
算机视觉产业的发展有望进一步带动对 Meta 深度学习库 PyTorch 以及其他 AI 互联网企业
深度学习库的需求，公司 adlik 软硬整体架构的需求有望提升。
图 2: Adlik 整体架构
测试效果如下图所示,在 ImageNet val 验证数据集上, ResNet50 剪枝模型经过蒸馏后精
度略有提升，剪枝模型的吞吐量比原始模型提升了 2.74 倍。INT8 量化后的模型的吞吐量
模型,在精度无损失的情况下,吞吐量比原始模型提升了 13.82 倍,效果显著。
目标检测 YOLOv5m 模型优化测试结果如下图所示,在 COCO2017 验证集上,YOLOv5m
经剪枝蒸馏和 INT8 量化后的模型，精度损失在 1%以内。优化后的 YOLOv5m 模型吞吐
量比原始模型提升了 3.39 倍。
盈利预测与投资评级
\triangleright
公司具有软件、硬件、芯片、操作系统等基础能力,将基础能力外溢赋能更多数字经济应用,
有望打开公司第二成长曲线。我们预计公司 2023-2025 年归母净利润分别为 101.90 亿元、
123.35 亿元、149.90 亿元,对应 PE 为 16.77 倍、13.85 倍、11.40 倍,维持“买入”评
风险因素
\triangleright
5G 建设不及预期、算力基础设施建设不及预期、中美贸易摩擦
研究团队简介
创证券、招商证券,2021 年 1 月加入信达证券研究开发中心,深度覆盖智能制造&云计算 IDC 产业链、海缆&通信新能
石瑜捷，通信行业研究助理，北京外国语大学金融学硕士，英语专业八级。曾就职于上海钢联 MRI 研究中心，负责汽
车板块研究。2020 年 12 月加入信达证券研究开发中心，从事通信行业研究工作，主要覆盖物联网、车载导航、智能
电网、运营商、5G 应用等领域。
陈光毅，通信组成员，北京大学物理学博士，凝聚态物理专业。2021年 12 月加入信达证券研究开发中心，从事通信
行业研究工作,主要覆盖海缆&通信新能源、激光雷达、车载控制器、云计算&5G等领域。
机构销售联系人
组成部分不曾与，不与，也将不会与本报告中的具体分析意见或观点直接或间接相关。
信达证券股份有限公司(以下简称“信达证券”)具有中国证监会批复的证券投资咨询业务资格。本报告由信达证券制作并发布。
本报告是针对与信达证券签署服务协议的签约客户的专属研究产品，为该类客户进行投资决策时提供辅助和参考，双方对权利与
义务均有严格约定。本报告仅提供给上述特定客户，并不面向公众发布。信达证券不会因接收人收到本报告而视其为本公司的当
版本为准。
本报告是基于信达证券认为可靠的已公开信息编制，但信达证券不保证所载信息的准确性和完整性。本报告所载的意见、评估及
预测仅为本报告最初出具日的观点和判断，本报告所指的证券或投资标的的价格、价值及投资收入可能会出现不同程度的波动，
涉及证券或投资标的的历史表现不应作为日后表现的保证。在不同时期，或因使用不同假设和标准，采用不同观点和分析方法，
致使信达证券发出与本报告所载意见、评估及预测不一致的研究报告，对此信达证券可不发出特别通知。
在任何情况下，本报告中的信息或所表述的意见并不构成对任何人的投资建议，也没有考虑到客户特殊的投资目标、财务状况或
需求。客户应考虑本报告中的任何意见或建议是否符合其特定状况，若有必要应寻求专家意见。本报告所载的资料、工具、意见
及推测仅供参考,并非作为或被视为出售或购买证券或其他投资标的的邀请或向人做出邀请。
在法律允许的情况下，信达证券或其关联机构可能会持有报告中涉及的公司所发行的证券并进行交易，并可能会为这些公司正在
提供或争取提供投资银行业务服务。
本报告版权仅为信达证券所有。未经信达证券书面同意，任何机构和个人不得以任何形式翻版、复制、发布、转发或引用本报告
的任何部分。若信达证券以外的机构向其客户发放本报告，则由该机构独自为此发送行为负责，信达证券对此等行为不承担任何
责任。本报告同时不构成信达证券向发送本报告的机构之客户提供的投资建议。
如未经信达证券授权，私自转载或者转发本报告，所引起的一切后果及法律责任由私自转载或转发者承担。信达证券将保留随时
追究其法律责任的权利。
评级说明
证券市场是一个风险无时不在的市场。投资者在进行证券交易时存在赢利的可能，也存在亏损的风险。建议投资者应当充分深入
地了解证券市场蕴含的各项风险并谨慎行事。
本报告中所述证券不一定能在所有的国家和地区向所有类型的投资者销售、投资者应当对本报告中的信息和意见进行独立评估、
并应同时考量各自的投资目的、财务状况和特定需求，必要时就法律、商业、财务、税收等方面咨询专业顾问的意见。在任何情
况下，信达证券不对任何人因使用本报告中的任何内容所引致的任何损失负任何责任，投资者需自行承担风险。