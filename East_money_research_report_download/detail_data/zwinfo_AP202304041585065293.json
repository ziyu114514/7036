{
  "attach_pages": "7",
  "attach_size": "819",
  "attach_type": "0",
  "attach_url": "https://pdf.dfcfw.com/pdf/H3_AP202304041585065293_1.pdf?1680605740000.pdf",
  "company_code": "80092742",
  "eitime": "2023-04-04 10:55:40",
  "extend": {},
  "info_code": "AP202304041585065293",
  "language": "0",
  "notice_content": "　　中兴通讯(000063)\r\n　　事件：中兴通讯作为算力龙头，在服务器、芯片、数据库等方面持续深度布局，有望受益于数字经济产业发展。\r\n　　点评：\r\n　　服务器：市场份额快速提升，保持较高增速\r\n　　据IDC数据，2022年中国服务器市场规模为273.4亿美元（1888.37亿人民币），同比增长9.1%，中兴通讯2022年服务器收入已达100.08亿元；根据中兴通讯官网，2022年，中兴通讯服务器及存储营业收入百亿元，同比增长近80%；据IDC2022年第四季度中国服务器市场跟踪报告，Top8服务器厂商中，浪潮、戴尔、联想份额均出现下滑，超聚变和中兴则取得明显增长，其中中兴通讯市场份额从3.1%提升至5.3%，位居国内第五。公司在今年新产品发布会上表示将快步实现服务器及储存产品国内前三（按照2022年份额超10%以上）、全球前五的经营愿景。\r\n　　运营商服务器市场：服务器产品实力强劲，在多个运营商项目中排名均位列第一\r\n　　1）公司在中国电信2022-2023年服务器集中采购中实现全标包入围，总份额第一，其中标包1、4、6中排名第一，标包2、3、7中位列第二。\r\n　　2）公司在中国联通2022云服务器集中采购中总份额第一，其中标包1排名第一；在2022-2024年中国联通国际服务器集中采购标段1中排名第二；在2022年中国联通人工智能服务器集中采购中排名第三；在2022年中国联通通用服务器集采中总份额第二。\r\n　　3）公司在中国移动2019-2020、2020PC服务器集采、2021-2022PC服务器集采（网络云标包）中均排名第一；在中国移动2021-2022PC服务器集采（第一批次）中总份额位列第二；在中国移动2021-2022PC服务器集采（第二批次，1-6标包）中总份额排名第三；在中国移动2022政企客户算力服务器集采中排名第二；在中国移动集中网络云资源池第三期工程计算型服务器采购中排名第一。\r\n　　我们认为2023年数字经济建设是国家发展主线之一，算网基础设施建设或将逐步加快，2023年三大运营商在算力方面的资本开支均保持20%以上增速，中兴通讯有望核心受益。\r\n　　AI服务器：产品性能强劲，成为“文心一言”可靠算力底座\r\n　　3月16日，据中兴通讯微信公众号，中兴通讯和百度联合宣布，中兴通讯服务器将支持百度“文心一言”，为AI产品应用提供更加强劲的算力支撑，助力AI产业化应用和生态繁荣。“文心一言”是百度基于文心大模型技术推出的生成式AI产品，具备跨模态、跨语言的深度语义理解与生成能力，“文心一言”将通过百度智能云对外提供服务，为产业带来AI普惠。\r\n　　在服务器产品方面，公司服务器产品全面满足百度定制化要求，针对百度智能云AI、深度学习的需求，中兴通讯服务器产品采用高密度、模块化、精细化设计，具有高性能、高可靠、易扩展、易管理等优势，在AI、云计算、大数据、NFV等领域具有出色的表现，适用于百度大脑、飞桨深度学习平台。目前，公司服务器产品已规模应用于百度智能云，充分满足百度智能云不同业务场景差异化配置需求、资源分配和上云服务。我们认为此次合作体现了公司在提供AI服务器解决方案方面的强大实力，公司服务器产品可充分满足AI模型所需的蓬勃算力需求和庞大的数据吞吐量需求。未来，随着国产AI模型持续发展，AI下游应用的落地，模型推理算力需求有望带动公司AI服务器持续放量。\r\n　　截至目前，公司最新的R6500G5GPU服务器可支持20张单宽半长GPU加速卡，具备高密度算力、灵活扩展、异构算力、海量存储、稳定可靠等特性，双路最大支持120核，AI性能提升10倍，为数字经济发展提供强大算力支持。\r\n　　联手英特尔发布深度学习推理软硬件架构，部分领域通过低成本CPU替代高成本GPU\r\n　　2022年12月28日，公司联合英特尔共同发布《英特尔联手中兴优化深度学习模型推理，实现降本增效》白皮书，本白皮书深入介绍了中兴通讯主导的开源项目Adlik如何与英特尔OpenVINO工具结合。为解决购买专用GPU硬件会大幅增加部署成本，而且应用范围有限，灵活度较低的问题，中兴通讯通过硬件创新和软件层面的深度优化，在部分场景中，如果能够直接使用CPU来进行推理，将有助于降低成本，提升灵活度，白皮书指出通过中兴Adlik可以对AI模型进行自动剪枝、蒸馏，实现模型大小的优化，再通过OpenVINO™的量化工具和推理引擎，对模型实现INT8量化，从而实现模型压缩，以降低模型推理所需的计算资源和内存带宽，提高模型的推理性能。通过使用中兴Adlik+第三代英特尔®至强®可扩展处理器+OpenVINO™工具套件的组合，可使已完成训练的高精度AI模型转换成参数较小、结构简单、精度基本不下降的AI小模型，其性能与大模型接近，模型数据吞吐量更高，从而实现在不增加GPU硬件，大幅减少部署成本的情况下，直接使用CPU服务器即可满足模型的日常推理需求，成功实现降本增效，并使得模型更易部署在算力有限的场景下，比如自动驾驶车端场景。我们认为此解决方案能够实现AI模型推理的降本增效，适用各垂直领域的AI小模型有望加速落地，充分满足不同场景需求。\r\n　　Adlik是用于将深度学习模型从训练完成到部署到特定硬件，提供应用服务的端到端工具链，其应用目的是为了将模型从研发产品快速部署到生产应用环境。Adlik可以和多种推理引擎协作，支持多款硬件，提供统一对外推理接口，并提供多种灵活的部署方案。目前谷歌TensorFLOW，脸书PyTorch和百度的PP飞桨深度学习库都已能够接入Adlik架构。\r\n　　测试效果如图3所示，在ImageNetval验证数据集上，ResNet50剪枝模型经过蒸馏后精度略有提升，剪枝模型的吞吐量比原始模型提升了2.74倍。INT8量化后的模型的吞吐量比未量化模型提升了2.96倍。经过Adlik剪枝蒸馏和INT8量化等方法优化后的ResNet50模型，在精度无损失的情况下，吞吐量比原始模型提升了13.82倍，效果显著。\r\n　　目标检测YOLOv5m模型优化测试结果如图4所示，在COCO2017验证集上，YOLOv5m经剪枝蒸馏和INT8量化后的模型，精度损失在1%以内。优化后的YOLOv5m模型吞吐量比原始模型提升了3.39倍。\r\n　　盈利预测与投资评级\r\n　　公司是全球领先的ICT解决方案提供商，公司作为主设备商龙头将充分受益5G建设加速，同时研发实力强劲，我们看好公司强劲技术研发实力在新应用领域的持续价值变现。预计公司2023-2025年净利润分别为101.90亿元、123.35亿元、149.90亿元，对应PE为15.00倍、12.39倍、10.20倍，维持“买入”评级。\r\n　　风险因素\r\n　　5G建设不及预期、智能汽车发展不及预期、中美贸易摩擦",
  "notice_date": "2023-04-04 00:00:00",
  "notice_title": "服务器规模国内前五，联手英特尔打造低成本AI架构",
  "page_size": 1,
  "page_size_ch": 0,
  "page_size_cht": 0,
  "page_size_en": 0,
  "rating": "BBB",
  "researcher": "蒋颖",
  "security": [
    {
      "market_uni": "0",
      "publish_relation": [
        {
          "originalCode": "448",
          "publishName": "通信设备"
        }
      ],
      "short_name": "中兴通讯",
      "short_name_ch": "中兴通讯",
      "short_name_cht": "中興通訊",
      "short_name_en": "ZTE",
      "stock": "000063"
    }
  ],
  "short_name": "中兴通讯",
  "source_sample_name": "信达证券",
  "star": "3"
}